{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <h1 style=\"text-align:center\"> Drexel University </h1>\n",
    "<h3 style = \"text-align:center\"> College of Computing and Informatics</h3>\n",
    "<h3 style = \"text-align:center\">INFO T780: Applied Machine Learning</h3>\n",
    "<h3 style = \"text-align:center\">GROUP 6: PROJECT TITLE : PASSENGER SURVIVAL PREDICTION ON TITANIC DATASET </h3>\n",
    "<h4> </h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEAM MEMBERS\n",
    "\n",
    "Tej Gottapu (tg672@drexel.edu)\n",
    "Dhilipan Dushendran(dd3255@drexel.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table of Contents:\n",
    "\n",
    "1) Introduction/Context\n",
    "\n",
    "2) Objective\n",
    "\n",
    "3) Data Overview\n",
    "\n",
    "4) Exploratory Data Analysis\n",
    "\n",
    "5) Data Preprocessing\n",
    "\n",
    "6) Models\n",
    "\n",
    "7) Procedure\n",
    "\n",
    "8) Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Introduction/Context\n",
    "\n",
    "RMS Titanic was a British passenger liner operated by the White Star Line that sank in the North Atlantic Ocean in the early morning hours of 15 April 1912, after striking an iceberg during her maiden voyage from Southampton to New York City. Of the estimated 2,224 passengers and crew aboard, more than 1,500 died, making the sinking one of modern history's deadliest peacetime commercial marine disasters. RMS Titanic was the largest ship afloat at the time she entered service and was the second of three Olympic-class ocean liners operated by the White Star Line.\n",
    "\n",
    "Courtesy : Wikipedia : https://en.wikipedia.org/wiki/RMS_Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Objective:\n",
    "\n",
    "The objective of the project is to use machine learning to create a model that predicts which passengers survived the Titanic shipwreck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Data Overview\n",
    "\n",
    "The data was obtained from a Kaggle competition https://www.kaggle.com/c/titanic/overview.\n",
    "\n",
    "The data from the Kaggle dataset was given in form of 'Train' and 'test' data .The train data is used to analyze the data and to train the model and it would be implemented on the tetsing dataset to find out the passenegr surival rate.Train.csv will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the “ground truth”.\n",
    "\n",
    "There are 12 columns in the training data.\n",
    "\n",
    "PassengerId : It indicates the Passenger id\n",
    "\n",
    "Survived' :  \"It is '0' or '1'. It indicates whether the passenger has survived or not.\n",
    "            if it's a \"\"1\"\", the passenger survived.\n",
    "            if it's a \"\"0\"\", the passenger died.\"\n",
    "\n",
    "Pclass' \tThere are three classes 1,2,3 (can be considered as Economy,Business and First)\n",
    "\n",
    "Name' : Passenger Name\n",
    "\n",
    "Sex' : Passenger gender\n",
    "\n",
    "Age' : Passenger age\n",
    "\n",
    "SibSp' : \"Sibling and Spouse\n",
    "\n",
    "Sibling = *brother, sister, stepbrother, stepsister* **\n",
    "Spouse =* husband, wife * **\"\n",
    "\n",
    "\n",
    "parch: Number of Parents/Children Aboard\n",
    "\n",
    "ticket : Ticket Number\n",
    "\n",
    "fare : Passenger Fare\n",
    "\n",
    "cabin : Cabin\n",
    "\n",
    "embarked : Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "\n",
    " \n",
    "The testing data has all the columns similar to the training data except the 'Survived' column which is present exclusively in the training data. We would predict the survival rate on the testing data based upon the training data.\n",
    "\n",
    "\n",
    "\n",
    "##### CATEGORICAL FEATURES:\n",
    "Sex, Embarked.\n",
    "\n",
    "##### CONTINUOUS FEATURES:\n",
    "AGE,FARE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#### Python Packages used:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz, DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from IPython.display import display\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import missingno as msno \n",
    "# to make this notebook's output identical at every run\n",
    "np.random.seed(42)\n",
    "# Ignore useless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External Modules to be installed\n",
    "1) 'missingno' is needs to be installed PIP : command : pip install missingno\n",
    "2)'Keras' needs to be installed in anaconda prompt. This is done using the command 'conda install -c conda-forge keras'\n",
    "\n",
    "Further documentation can be found below:\n",
    "\n",
    "https://anaconda.org/conda-forge/keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Exploratory Data Analysis\n",
    "\n",
    "Exploratory Data Anlaysis was done in the following ways :\n",
    "\n",
    "a) PLOT FOR THE NUMBER OF SURVIVORS\n",
    "b) VISUALIZATION BETWEEN PASSENGER CLASS AND SURVIVORS\n",
    "c) Plot between survival rate with Sex and Pclass\n",
    "d) FREQUENCY OF SURVIVORS VS NON-SURVIVORS\n",
    "e) EMBARKED LOCATIONS VS PASSENGERS VS SURVIVORS\n",
    "f) Correlation was plotted between the target variable ' Survived' and the remaining attributes in the dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Data Preprocessing\n",
    "\n",
    " MISSING VALUES :\n",
    "\n",
    "The following columns have missing values\n",
    "\n",
    "Age            177\n",
    "Cabin          687\n",
    "Embarked         2\n",
    "\n",
    "And the amount of data missing from Cabin column is so large that it can not be altered or removed as the total data is less, whereas Age has 177 missing values which can be filled with the mean of the corresponding passenger category.\n",
    "\n",
    "Finally, the column embarked has only 2 missing values. This column represents the point of boarding , with the help of below plot we can come to a reasonable conclusion that the value \"C\" has higher fare and the fare of missing value is also on the high range(i.e. Fare = 80).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6)MODELS:\n",
    "\n",
    "\n",
    "\n",
    "The following machine learning models have been used :\n",
    "\n",
    "1)Logistic Regression : \n",
    "\n",
    "Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression[1] (or logit regression) is estimating the parameters of a logistic model (a form of binary regression).( source : Wikipedia)\n",
    "\n",
    "2)Decision Tree:\n",
    "\n",
    "Decision tree learning is one of the predictive modelling approaches used in statistics, data mining and machine learning. It uses a decision tree (as a predictive model) to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. (source : Wikipedia)\n",
    "\n",
    "Here , we use DECISION TREE CLASSIFIER\n",
    "\n",
    "3)Support Vector Machine (SVC):\n",
    "\n",
    "In machine learning, support-vector machines (SVMs, also support-vector networks[1]) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis.(source : Wikipedia)\n",
    "\n",
    "4) Random Forest Classifier:\n",
    "\n",
    "Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.(source : Wikipedia)\n",
    "\n",
    "5) Artificial Neural Network:\n",
    "\n",
    "Artificial neural networks (ANNs), usually simply called neural networks (NNs), are computing systems vaguely inspired by the biological neural networks that constitute animal brains.An ANN is based on a collection of connected units or nodes called artificial neurons, which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit a signal to other neurons. An artificial neuron that receives a signal then processes it and can signal neurons connected to it.(source : Wikipedia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7) Procedure:\n",
    "\n",
    "The data was split in test and train after pre-preocessing has been done and the performance of the models is measured using various metrics such as Accuracy,Precision,Recall,F1_score. In addition to it, the following were calculated for the models.\n",
    "\n",
    "MSE : Mean squared error\n",
    "\n",
    "RMSE : Root Mean Square Error \n",
    "\n",
    "MAE : Mean absolute error \n",
    "\n",
    "Hyperparamter using GridSearchCV was implemented on the models so as to improve the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Conclusion:\n",
    "\n",
    "As part of our implementation we have applied the models on the data and compared the performance after applying hyperparamter tuning and observed that there is only minimal increase/decrease in the performance metrics such as Precision,Recall,F1_score and Accuracy. Accuracy has increased for decision tree and decrease for Random Forest after hyperparameter and tuning and there is no change for Support Vector Machine and Logistic Regression.\n",
    "\n",
    "There is an increases in precision  for Decision Tree and it decreases for Random Forest after hyperparamater tuninng.\n",
    "Recall value increases for Decision tree, Support Vector Machine and it decreases for Random Forest.\n",
    "\n",
    "F1_score increases for Decision Tree and decreases for Random Forest and there is no significant change on other models.\n",
    "Binning can be applied on certain features so as to improve performance and additional hyperparameter tuning concepts such as RandomSearchCV to further hypertune the models.\n",
    "##### AN OUTPUT FILE WILL BE CREATED WITH NAME 'Passernger_Survival_Predicted_Output' comparing the actual and predicted outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
